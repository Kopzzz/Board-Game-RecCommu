{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Surprise version: 1.1.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import surprise\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Surprise version: {surprise.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>10 Days in Europe</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>12 Days</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>7 Wonders</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>A Column of Fire</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>A Feast for Odin</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userID             itemID  rating\n",
       "0  1 Family Meeple  10 Days in Europe    2.05\n",
       "1  1 Family Meeple            12 Days    3.50\n",
       "2  1 Family Meeple          7 Wonders    3.25\n",
       "3  1 Family Meeple   A Column of Fire    2.50\n",
       "4  1 Family Meeple   A Feast for Odin    5.00"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/reviews-cleaned.csv')\n",
    "df = df.rename(columns={'user':'userID', 'name':'itemID'})\n",
    "df['rating'] = df['rating'] / 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x184ba128190>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = python_random_split(df, 0.75)\n",
    "train_set = surprise.Dataset.load_from_df(train, reader=surprise.Reader('ml-100k')).build_full_trainset()\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "svd = surprise.SVD(random_state=0, n_factors=200, n_epochs=40, verbose=True)\n",
    "\n",
    "with Timer() as train_time:\n",
    "    for epoch in range(30):  # Set the maximum number of epochs\n",
    "        svd.fit(train_set)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        predictions = svd.test(test_set)\n",
    "        \n",
    "        # Compute RMSE\n",
    "        current_rmse = accuracy.rmse(predictions)\n",
    "        print(f\"Epoch {epoch + 1} - Test RMSE: {current_rmse}\")\n",
    "        \n",
    "        # Check if RMSE is increasing\n",
    "        if current_rmse > prev_rmse + tolerance:\n",
    "            print(\"Stopping training as RMSE is increasing.\")\n",
    "            break\n",
    "        \n",
    "        prev_rmse = current_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cop\\OneDrive - KASETSART UNIVERSITY\\Documents\\GitHub\\Board-Game-RecCommu\\code\\7_deep_rec.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m svd \u001b[39m=\u001b[39m surprise\u001b[39m.\u001b[39mSVD(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, n_factors\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, n_epochs\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m Timer() \u001b[39mas\u001b[39;00m train_time:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     svd\u001b[39m.\u001b[39;49mfit(train_set)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTook \u001b[39m\u001b[39m{\u001b[39;00mtrain_time\u001b[39m.\u001b[39minterval\u001b[39m}\u001b[39;00m\u001b[39m seconds for training.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:155\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:228\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\surprise\\trainset.py:193\u001b[0m, in \u001b[0;36mTrainset.all_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generator function to iterate over all ratings.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \n\u001b[0;32m    187\u001b[0m \u001b[39mYields:\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m    A tuple ``(uid, iid, rating)`` where ids are inner ids (see\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m    :ref:`this note <raw_inner_note>`).\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[39mfor\u001b[39;00m u, u_ratings \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mur\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m u_ratings:\n\u001b[0;32m    194\u001b[0m         \u001b[39myield\u001b[39;00m u, i, r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svd = surprise.SVD(random_state=0, n_factors=200, n_epochs=40, verbose=True)\n",
    "\n",
    "with Timer() as train_time:\n",
    "    svd.fit(train_set)\n",
    "    \n",
    "print(f\"Took {train_time.interval} seconds for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twohu2001</td>\n",
       "      <td>Dream Home</td>\n",
       "      <td>3.400390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strubs42</td>\n",
       "      <td>Chimera Station</td>\n",
       "      <td>3.426129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnus the Blue</td>\n",
       "      <td>Ticket to Ride: The Card Game</td>\n",
       "      <td>2.855045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dontylw</td>\n",
       "      <td>Thurn and Taxis</td>\n",
       "      <td>3.402530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hessu68</td>\n",
       "      <td>Room 25</td>\n",
       "      <td>2.968334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userID                         itemID  prediction\n",
       "0        twohu2001                     Dream Home    3.400390\n",
       "1         strubs42                Chimera Station    3.426129\n",
       "2  Magnus the Blue  Ticket to Ride: The Card Game    2.855045\n",
       "3          dontylw                Thurn and Taxis    3.402530\n",
       "4          Hessu68                        Room 25    2.968334"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(svd, test, usercol='userID', itemcol='itemID')\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twohu2001</td>\n",
       "      <td>Dream Home</td>\n",
       "      <td>3.392358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strubs42</td>\n",
       "      <td>Chimera Station</td>\n",
       "      <td>3.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnus the Blue</td>\n",
       "      <td>Ticket to Ride: The Card Game</td>\n",
       "      <td>2.775777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dontylw</td>\n",
       "      <td>Thurn and Taxis</td>\n",
       "      <td>3.380153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hessu68</td>\n",
       "      <td>Room 25</td>\n",
       "      <td>2.906880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userID                         itemID  prediction\n",
       "0        twohu2001                     Dream Home    3.392358\n",
       "1         strubs42                Chimera Station    3.415000\n",
       "2  Magnus the Blue  Ticket to Ride: The Card Game    2.775777\n",
       "3          dontylw                Thurn and Taxis    3.380153\n",
       "4          Hessu68                        Room 25    2.906880"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(svd, test, usercol='userID', itemcol='itemID')\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = test[:1]\n",
    "# df_test['userID'] = 'kop'\n",
    "# df_test['itemID'] = 'Ticket to Ride: The Card Game'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict(svd, df_test, usercol='userID', itemcol='itemID')\n",
    "# predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 371.59553730000005 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "    all_predictions = compute_ranking_predictions(svd, train, usercol='userID', itemcol='itemID', remove_seen=True)\n",
    "    \n",
    "print(f\"Took {test_time.interval} seconds for prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t0.559294\n",
      "MAE:\t\t0.412656\n",
      "rsquared:\t0.397795\n",
      "exp var:\t0.397801\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "eval_rmse = rmse(test, predictions)\n",
    "eval_mae = mae(test, predictions)\n",
    "eval_rsquared = rsquared(test, predictions)\n",
    "eval_exp_var = exp_var(test, predictions)\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t0.559032\n",
      "MAE:\t\t0.412289\n",
      "rsquared:\t0.398359\n",
      "exp var:\t0.398361\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "eval_rmse = rmse(test, predictions)\n",
    "eval_mae = mae(test, predictions)\n",
    "eval_rsquared = rsquared(test, predictions)\n",
    "eval_exp_var = exp_var(test, predictions)\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t0.590728\n",
      "MAE:\t\t0.437791\n",
      "rsquared:\t0.328201\n",
      "exp var:\t0.328201\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 10\n",
    "\n",
    "eval_rmse = rmse(test, predictions)\n",
    "eval_mae = mae(test, predictions)\n",
    "eval_rsquared = rsquared(test, predictions)\n",
    "eval_exp_var = exp_var(test, predictions)\n",
    "\n",
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "\n",
    "\n",
    "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "      \"MAE:\\t\\t%f\" % eval_mae,\n",
    "      \"rsquared:\\t%f\" % eval_rsquared,\n",
    "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')\n",
    "\n",
    "print('----')\n",
    "\n",
    "print(\"MAP:\\t\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard VAE\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flatbuffers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cop\\OneDrive - KASETSART UNIVERSITY\\Documents\\GitHub\\Board-Game-RecCommu\\code\\7_deep_rec.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# sns.set()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_deep_rec.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm \n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\__init__.py:52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:37\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:37\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py:48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg\n\u001b[1;32m---> 48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m lite\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m lookup\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m constants\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m \u001b[39mimport\u001b[39;00m Interpreter\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m \u001b[39mimport\u001b[39;00m OpHint\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\experimental\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf.lite.experimental namespace.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m authoring\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalyzer\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelAnalyzer \u001b[39mas\u001b[39;00m Analyzer\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m \u001b[39mimport\u001b[39;00m OpResolverType\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\experimental\\authoring\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf.lite.experimental.authoring namespace.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauthoring\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauthoring\u001b[39;00m \u001b[39mimport\u001b[39;00m compatible\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\authoring\\authoring.py:43\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m lite\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m converter_error_data_pb2\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmlir\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstablehlo\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization_options_pb2 \u001b[39mas\u001b[39;00m quant_opts_pb2\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m lite_constants\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m util\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m wrap_toco\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvert_phase\u001b[39;00m \u001b[39mimport\u001b[39;00m Component\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\util.py:23\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[1;32m---> 23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mflatbuffers\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m graph_debug_info_pb2\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2 \u001b[39mas\u001b[39;00m _config_pb2\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flatbuffers'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tqdm import tqdm \n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "# from recommenders.datasets import movielens\n",
    "from recommenders.datasets.split_utils import min_rating_filter_pandas\n",
    "from recommenders.datasets.python_splitters import numpy_stratified_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "\n",
    "from recommenders.datasets.sparse import AffinityMatrix\n",
    "from recommenders.utils.python_utils import binarize\n",
    "from recommenders.models.vae.standard_vae import StandardVAE\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 100 items to recommend\n",
    "TOP_K = 100\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '1m'\n",
    "\n",
    "# Model parameters\n",
    "HELDOUT_USERS = 10 # CHANGE FOR DIFFERENT DATASIZE\n",
    "INTERMEDIATE_DIM = 200\n",
    "LATENT_DIM = 70\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# temporary Path to save the optimal model's weights\n",
    "tmp_dir = '../model'\n",
    "WEIGHTS_PATH = os.path.join(tmp_dir, \"svae_weights.hdf5\")\n",
    "\n",
    "SEED = 98765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>10 Days in Europe</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>12 Days</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>7 Wonders</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>A Column of Fire</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>A Feast for Odin</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userID             itemID  rating\n",
       "0  1 Family Meeple  10 Days in Europe     4.1\n",
       "1  1 Family Meeple            12 Days     7.0\n",
       "2  1 Family Meeple          7 Wonders     6.5\n",
       "3  1 Family Meeple   A Column of Fire     5.0\n",
       "4  1 Family Meeple   A Feast for Odin    10.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/reviews-cleaned.csv')\n",
    "df = df[:100000]\n",
    "df = df.rename(columns={'user':'userID', 'name':'itemID'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58538, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>12 Days</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>A Feast for Odin</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Above and Below</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Abyss</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Africana</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Agricola</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Agricola (Revised Edition)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Akrotiri</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Alien Frontiers</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1 Family Meeple</td>\n",
       "      <td>Altiplano</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userID                      itemID  rating\n",
       "1   1 Family Meeple                     12 Days     7.0\n",
       "4   1 Family Meeple            A Feast for Odin    10.0\n",
       "5   1 Family Meeple             Above and Below     9.0\n",
       "6   1 Family Meeple                       Abyss     8.0\n",
       "7   1 Family Meeple                    Africana     7.0\n",
       "11  1 Family Meeple                    Agricola     7.0\n",
       "12  1 Family Meeple  Agricola (Revised Edition)     8.0\n",
       "13  1 Family Meeple                    Akrotiri     8.0\n",
       "14  1 Family Meeple             Alien Frontiers     8.0\n",
       "15  1 Family Meeple                   Altiplano     8.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarize the data (only keep ratings >= 7)\n",
    "df_preferred = df[df['rating'] >= 7]\n",
    "print (df_preferred.shape)\n",
    "df_low_rating = df[df['rating'] < 7]\n",
    "\n",
    "df_preferred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep users who clicked on at least 5 movies\n",
    "# df = min_rating_filter_pandas(df_preferred, min_rating=5, filter_by=\"user\")\n",
    "\n",
    "# # Keep movies that were clicked on by at least on 1 user\n",
    "# df = min_rating_filter_pandas(df, min_rating=1, filter_by=\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 100000 watching events from 154 users and 4506 movies (sparsity: 14.411%)\n"
     ]
    }
   ],
   "source": [
    "# Obtain both usercount and itemcount after filtering\n",
    "usercount = df[['userID']].groupby('userID', as_index = False).size()\n",
    "itemcount = df[['itemID']].groupby('itemID', as_index = False).size()\n",
    "\n",
    "# Compute sparsity after filtering\n",
    "sparsity = 1. * df.shape[0] / (usercount.shape[0] * itemcount.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (df.shape[0], usercount.shape[0], itemcount.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = sorted(df.userID.unique())\n",
    "np.random.seed(SEED)\n",
    "unique_users = np.random.permutation(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 154\n",
      "\n",
      "Number of training users: 134\n",
      "\n",
      "Number of validation users: 10\n",
      "\n",
      "Number of test users: 10\n"
     ]
    }
   ],
   "source": [
    "# Create train/validation/test users\n",
    "n_users = len(unique_users)\n",
    "print(\"Number of unique users:\", n_users)\n",
    "\n",
    "train_users = unique_users[:(n_users - HELDOUT_USERS * 2)]\n",
    "print(\"\\nNumber of training users:\", len(train_users))\n",
    "\n",
    "val_users = unique_users[(n_users - HELDOUT_USERS * 2) : (n_users - HELDOUT_USERS)]\n",
    "print(\"\\nNumber of validation users:\", len(val_users))\n",
    "\n",
    "test_users = unique_users[(n_users - HELDOUT_USERS):]\n",
    "print(\"\\nNumber of test users:\", len(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training observations:  87541\n",
      "\n",
      "Number of validation observations:  6555\n",
      "\n",
      "Number of test observations:  5904\n"
     ]
    }
   ],
   "source": [
    "# For training set keep only users that are in train_users list\n",
    "train_set = df.loc[df['userID'].isin(train_users)]\n",
    "print(\"Number of training observations: \", train_set.shape[0])\n",
    "\n",
    "# For validation set keep only users that are in val_users list\n",
    "val_set = df.loc[df['userID'].isin(val_users)]\n",
    "print(\"\\nNumber of validation observations: \", val_set.shape[0])\n",
    "\n",
    "# For test set keep only users that are in test_users list\n",
    "test_set = df.loc[df['userID'].isin(test_users)]\n",
    "print(\"\\nNumber of test observations: \", test_set.shape[0])\n",
    "\n",
    "# train_set/val_set/test_set contain user - movie interactions with rating 4 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique movies that rated in training set 4485\n"
     ]
    }
   ],
   "source": [
    "# Obtain list of unique movies used in training set\n",
    "unique_train_items = pd.unique(train_set['itemID'])\n",
    "print(\"Number of unique movies that rated in training set\", unique_train_items.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation observations after filtering:  6542\n",
      "\n",
      "Number of test observations after filtering:  5893\n"
     ]
    }
   ],
   "source": [
    "# For validation set keep only movies that used in training set\n",
    "val_set = val_set.loc[val_set['itemID'].isin(unique_train_items)]\n",
    "print(\"Number of validation observations after filtering: \", val_set.shape[0])\n",
    "\n",
    "# For test set keep only movies that used in training set\n",
    "test_set = test_set.loc[test_set['itemID'].isin(unique_train_items)]\n",
    "print(\"\\nNumber of test observations after filtering: \", test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the sparse matrix generation for train, validation and test sets\n",
    "# use list of unique items from training set for all sets\n",
    "am_train = AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
    "\n",
    "am_val = AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
    "\n",
    "am_test = AffinityMatrix(df=test_set, items_list=unique_train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 4485)\n",
      "(10, 4485)\n",
      "(10, 4485)\n"
     ]
    }
   ],
   "source": [
    "# Obtain the sparse matrix for train, validation and test sets\n",
    "train_data, _, _ = am_train.gen_affinity_matrix()\n",
    "print(train_data.shape)\n",
    "\n",
    "val_data, val_map_users, val_map_items = am_val.gen_affinity_matrix()\n",
    "print(val_data.shape)\n",
    "\n",
    "test_data, test_map_users, test_map_items = am_test.gen_affinity_matrix()\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation and test data into training and testing parts\n",
    "val_data_tr, val_data_te = numpy_stratified_split(val_data, ratio=0.75, seed=SEED)\n",
    "test_data_tr, test_data_te = numpy_stratified_split(test_data, ratio=0.75, seed=SEED)\n",
    "\n",
    "# Binarize train, validation and test data\n",
    "train_data = binarize(a=train_data, threshold=3.5)\n",
    "val_data = binarize(a=val_data, threshold=3.5)\n",
    "test_data = binarize(a=test_data, threshold=3.5)\n",
    "\n",
    "# Binarize validation data: training part  \n",
    "val_data_tr = binarize(a=val_data_tr, threshold=3.5)\n",
    "\n",
    "# Binarize validation data: testing part (save non-binary version in the separate object, will be used for calculating NDCG)\n",
    "val_data_te_ratings = val_data_te.copy()\n",
    "val_data_te = binarize(a=val_data_te, threshold=3.5)\n",
    "\n",
    "# Binarize test data: training part \n",
    "test_data_tr = binarize(a=test_data_tr, threshold=3.5)\n",
    "\n",
    "# Binarize test data: testing part (save non-binary version in the separate object, will be used for calculating NDCG)\n",
    "test_data_te_ratings = test_data_te.copy()\n",
    "test_data_te = binarize(a=test_data_te, threshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|         | 1238/41462 [00:00<00:07, 5588.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|| 41462/41462 [00:03<00:00, 10617.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# retrieve real ratings from initial dataset \n",
    "\n",
    "test_data_te_ratings=pd.DataFrame(test_data_te_ratings)\n",
    "val_data_te_ratings=pd.DataFrame(val_data_te_ratings)\n",
    "\n",
    "total_iterations = len(df_low_rating)\n",
    "\n",
    "for index,i in tqdm(df_low_rating.iterrows(), total=total_iterations, desc=\"Processing Rows\"):\n",
    "  user_old= i['userID'] # old value \n",
    "  item_old=i['itemID'] # old value \n",
    "\n",
    "  if (test_map_users.get(user_old) is not None)  and (test_map_items.get(item_old) is not None) :\n",
    "      user_new=test_map_users.get(user_old) # new value \n",
    "      item_new=test_map_items.get(item_old) # new value \n",
    "      rating=i['rating'] \n",
    "      test_data_te_ratings.at[user_new,item_new]= rating   \n",
    "\n",
    "  if (val_map_users.get(user_old) is not None)  and (val_map_items.get(item_old) is not None) :\n",
    "      user_new=val_map_users.get(user_old) # new value \n",
    "      item_new=val_map_items.get(item_old) # new value \n",
    "      rating=i['rating'] \n",
    "      val_data_te_ratings.at[user_new,item_new]= rating   \n",
    "\n",
    "\n",
    "val_data_te_ratings=val_data_te_ratings.to_numpy()    \n",
    "test_data_te_ratings=test_data_te_ratings.to_numpy()    \n",
    "# test_data_te_ratings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_anneal = StandardVAE(n_users=train_data.shape[0], # Number of unique users in the training set\n",
    "                                   original_dim=train_data.shape[1], # Number of unique items in the training set\n",
    "                                   intermediate_dim=INTERMEDIATE_DIM, \n",
    "                                   latent_dim=LATENT_DIM, \n",
    "                                   n_epochs=EPOCHS, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   k=TOP_K,\n",
    "                                   verbose=0,\n",
    "                                   seed=SEED,\n",
    "                                   save_path=WEIGHTS_PATH,\n",
    "                                   drop_encoder=0.5,\n",
    "                                   drop_decoder=0.5,\n",
    "                                   annealing=False,\n",
    "                                   beta=1.0\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_train = AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
    "\n",
    "am_val = AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
    "\n",
    "am_test = AffinityMatrix(df=test_set, items_list=unique_train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 239, in __call__\n        self._loss_metric.update_state(\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics\\base_metric.py\", line 449, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\keras_tensor.py\", line 254, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_2'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cop\\OneDrive - KASETSART UNIVERSITY\\Documents\\GitHub\\Board-Game-RecCommu\\code\\7_standard_vae.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m Timer() \u001b[39mas\u001b[39;00m t:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model_without_anneal\u001b[39m.\u001b[39;49mfit(x_train\u001b[39m=\u001b[39;49mtrain_data, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                              x_valid\u001b[39m=\u001b[39;49mval_data, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                              x_val_tr\u001b[39m=\u001b[39;49mval_data_tr, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                              x_val_te\u001b[39m=\u001b[39;49mval_data_te_ratings, \u001b[39m# with the original ratings \u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                              mapper\u001b[39m=\u001b[39;49mam_val,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                              )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Cop/OneDrive%20-%20KASETSART%20UNIVERSITY/Documents/GitHub/Board-Game-RecCommu/code/7_standard_vae.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTook \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m seconds for training.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(t))\n",
      "File \u001b[1;32mc:\\Users\\Cop\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\recommenders\\models\\vae\\standard_vae.py:402\u001b[0m, in \u001b[0;36mStandardVAE.fit\u001b[1;34m(self, x_train, x_valid, x_val_tr, x_val_te, mapper)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mls_beta \u001b[39m=\u001b[39m anneal\u001b[39m.\u001b[39mget_data()\n\u001b[0;32m    401\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m    403\u001b[0m         generator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn_batch_generator(x_train),\n\u001b[0;32m    404\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumber_of_batches,\n\u001b[0;32m    405\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_epochs,\n\u001b[0;32m    406\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    407\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[metrics, history, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce_lr],\n\u001b[0;32m    408\u001b[0m         validation_data\u001b[39m=\u001b[39;49m(x_valid, x_valid),\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    411\u001b[0m \u001b[39m# save lists\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loss \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mlosses\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m \n\u001b[0;32m   2251\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2252\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2256\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2257\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2258\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   2259\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> 2260\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2261\u001b[0m     generator,\n\u001b[0;32m   2262\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2263\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2264\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2265\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2266\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2267\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2268\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2269\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2270\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2271\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2272\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2273\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2274\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filek0_w_fwh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\compile_utils.py\", line 239, in __call__\n        self._loss_metric.update_state(\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\metrics\\base_metric.py\", line 449, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"C:\\Users\\Cop\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\keras_tensor.py\", line 254, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_2'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    model_without_anneal.fit(x_train=train_data, \n",
    "                             x_valid=val_data, \n",
    "                             x_val_tr=val_data_tr, \n",
    "                             x_val_te=val_data_te_ratings, # with the original ratings \n",
    "                             mapper=am_val,\n",
    "                             )\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d04d0ea025a2b5c0a405c24c3ed943d49065a11de485e353892bf0638615a3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
